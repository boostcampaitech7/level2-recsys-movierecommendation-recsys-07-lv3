{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import bisect\n",
    "from tqdm import tqdm\n",
    "import bottleneck as bn\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 학습 데이터와 메타데이터 로드 \n",
    "train_ratings = pd.read_csv('/data/ephemeral/home/data/train/train_ratings.csv')\n",
    "titles = pd.read_csv('/data/ephemeral/home/data/train/titles.tsv', sep='\\t')\n",
    "years = pd.read_csv('/data/ephemeral/home/data/train/years.tsv', sep='\\t')\n",
    "\n",
    "# 누락된 item 확인\n",
    "train_items = set(train_ratings['item'].unique())\n",
    "years_items = set(years['item'].unique())\n",
    "\n",
    "missing_years = train_items - years_items\n",
    "\n",
    "# 누락된 item의 제목 확인\n",
    "missing_years_titles = titles[titles['item'].isin(missing_years)].copy()\n",
    "\n",
    "# 연도 추출을 위한 함수 정의\n",
    "def extract_year(title):\n",
    "    match = re.search(r'\\((\\d{4})\\)', title)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return -1  # 연도를 찾지 못한 경우 -1로 설정\n",
    "\n",
    "# 누락된 item의 연도 추출\n",
    "missing_years_titles['year'] = missing_years_titles['title'].apply(extract_year)\n",
    "\n",
    "# 추출된 연도 정보를 years 데이터프레임에 추가\n",
    "years = pd.concat([years, missing_years_titles[['item', 'year']]], ignore_index=True)\n",
    "\n",
    "# 학습 데이터와 업데이트된 years 데이터 병합\n",
    "train_ratings = train_ratings.merge(years, on='item', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_column(data, column_name,start_index=1):\n",
    "    \"\"\"\n",
    "    Reindex a column in the dataframe to ensure continuous indices starting from 0.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pd.DataFrame, the input dataframe.\n",
    "    - column_name: str, the column to reindex.\n",
    "\n",
    "    Returns:\n",
    "    - data: pd.DataFrame, the dataframe with reindexed column.\n",
    "    - mapping_dict: dict, the original-to-new mapping dictionary.\n",
    "    \"\"\"\n",
    "    unique_values = data[column_name].unique()\n",
    "    mapping_dict = {original_id: new_id for new_id, original_id in enumerate(unique_values, start=start_index)}\n",
    "    data[column_name] = data[column_name].map(mapping_dict)\n",
    "    return data, mapping_dict\n",
    "\n",
    "# 유저 및 아이템 리인덱싱\n",
    "train_ratings, usr2idx_dict = reindex_column(train_ratings, 'user', start_index=0)  # Users can start from 0\n",
    "train_ratings, item2idx_dict = reindex_column(train_ratings, 'item', start_index=1)  # Items start from 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_validation_split 함수 정의\n",
    "def train_validation_split(interaction_matrix: csr_matrix, num_random_items: int = 2) -> Tuple[csr_matrix, csr_matrix]:\n",
    "    \"\"\"\n",
    "    Split a CSR interaction matrix into training and validation sets with specific rules:\n",
    "    - Last interaction is always included in the validation set.\n",
    "    - Additional 'num_random_items' interactions are randomly selected for the validation set.\n",
    "\n",
    "    Parameters:\n",
    "    - interaction_matrix: csr_matrix, the full user-item interaction matrix.\n",
    "    - num_random_items: int, number of additional random interactions to include in the validation set.\n",
    "\n",
    "    Returns:\n",
    "    - train_matrix: csr_matrix, training set interactions.\n",
    "    - validation_matrix: csr_matrix, validation set interactions.\n",
    "    \"\"\"\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    val_rows, val_cols, val_data = [], [], []\n",
    "\n",
    "    num_users = interaction_matrix.shape[0]\n",
    "\n",
    "    for user in range(num_users):\n",
    "        # Get the non-zero interactions (item indices) for this user\n",
    "        item_indices = interaction_matrix[user].indices\n",
    "        num_items = len(item_indices)\n",
    "\n",
    "        if num_items == 0:\n",
    "            continue  # Skip users with no interactions\n",
    "\n",
    "        # Last interaction is always included in the validation set\n",
    "        val_items = [item_indices[-1]]\n",
    "\n",
    "        # Determine the number of random items to sample\n",
    "        if num_items > 1:\n",
    "            available_items = item_indices[:-1]\n",
    "            actual_num_random = min(num_random_items, len(available_items))\n",
    "            if actual_num_random > 0:\n",
    "                random_items = np.random.choice(available_items, size=actual_num_random, replace=False)\n",
    "                val_items.extend(random_items)\n",
    "\n",
    "        # Add the remaining items to the training set\n",
    "        train_items = list(set(item_indices) - set(val_items))\n",
    "\n",
    "        # Add training interactions\n",
    "        train_rows.extend([user] * len(train_items))\n",
    "        train_cols.extend(train_items)\n",
    "        train_data.extend([1] * len(train_items))\n",
    "\n",
    "        # Add validation interactions\n",
    "        val_rows.extend([user] * len(val_items))\n",
    "        val_cols.extend(val_items)\n",
    "        val_data.extend([1] * len(val_items))\n",
    "\n",
    "    # Create CSR matrices for training and validation\n",
    "    train_matrix = csr_matrix((train_data, (train_rows, train_cols)), dtype='float64', shape=interaction_matrix.shape)\n",
    "    validation_matrix = csr_matrix((val_data, (val_rows, val_cols)), dtype='float64', shape=interaction_matrix.shape)\n",
    "\n",
    "    return train_matrix, validation_matrix\n",
    "\n",
    "# 사용자-아이템 인터랙션 행렬 생성\n",
    "rows, cols = train_ratings['user'].values, train_ratings['item'].values\n",
    "feedback = np.ones_like(rows)\n",
    "\n",
    "num_users, num_items = train_ratings['user'].nunique(), train_ratings['item'].nunique()\n",
    "interaction_matrix = csr_matrix((feedback, (rows, cols)), dtype='float64', shape=(num_users, num_items + 1))\n",
    "\n",
    "# Train/Validation 분할 (num_random_items를 2로 설정)\n",
    "train_matrix, validation_matrix = train_validation_split(interaction_matrix, num_random_items=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    \"\"\"\n",
    "    Recall@k를 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_pred: numpy.ndarray, 모든 아이템에 대한 예측 점수.\n",
    "    - heldout_batch: numpy.ndarray or csr_matrix, 실제 상호작용 행렬.\n",
    "    - k: int, 컷오프 값.\n",
    "    \n",
    "    Returns:\n",
    "    - recall: numpy.ndarray, 각 사용자에 대한 Recall@k.\n",
    "    \"\"\"\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)[:, :k]  # 상위 k 인덱스 찾기\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx] = True\n",
    "\n",
    "    # heldout_batch가 희소 행렬인 경우 밀집 배열로 변환\n",
    "    if isinstance(heldout_batch, np.ndarray):\n",
    "        X_true_binary = heldout_batch > 0\n",
    "    else:\n",
    "        X_true_binary = (heldout_batch > 0).toarray()\n",
    "\n",
    "    # Recall@k 계산\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall\n",
    "\n",
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    \"\"\"\n",
    "    NDCG@k를 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_pred: numpy.ndarray, 모든 아이템에 대한 예측 점수.\n",
    "    - heldout_batch: numpy.ndarray or csr_matrix, 실제 상호작용 행렬.\n",
    "    - k: int, 컷오프 값.\n",
    "    \n",
    "    Returns:\n",
    "    - ndcg: numpy.ndarray, 각 사용자에 대한 NDCG@k.\n",
    "    \"\"\"\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)[:, :k]\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk_part]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "\n",
    "    # heldout_batch가 희소 행렬인 경우 밀집 배열로 변환\n",
    "    if isinstance(heldout_batch, np.ndarray):\n",
    "        X_true_binary = heldout_batch > 0\n",
    "    else:\n",
    "        X_true_binary = (heldout_batch > 0).toarray()\n",
    "\n",
    "    # DCG 계산\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "    DCG = (X_true_binary[np.arange(batch_users)[:, np.newaxis], idx_topk] * tp).sum(axis=1)\n",
    "\n",
    "    # IDCG 계산\n",
    "    IDCG = np.array([tp[:min(n, k)].sum() for n in X_true_binary.sum(axis=1)])\n",
    "    ndcg = DCG / IDCG\n",
    "    ndcg[np.isnan(ndcg)] = 0.0  # 상호작용이 없는 사용자에 대한 NaN 처리\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(sequence, max_length=50, padding_value=0):\n",
    "    \"\"\"\n",
    "    Crop the sequence to a maximum length from the end and pad if necessary.\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence: list of int, 아이템 인덱스 시퀀스.\n",
    "    - max_length: int, 최대 시퀀스 길이.\n",
    "    - padding_value: int, 패딩에 사용할 값 (기본값: 0).\n",
    "    \n",
    "    Returns:\n",
    "    - sequence: list of int, 고정된 길이의 시퀀스.\n",
    "    \"\"\"\n",
    "    if len(sequence) > max_length:\n",
    "        sequence = sequence[-max_length:]\n",
    "    else:\n",
    "        sequence = [padding_value] * (max_length - len(sequence)) + sequence\n",
    "    return sequence\n",
    "\n",
    "def mask(sequence, mask_ratio=0.2, mask_token=0):\n",
    "    \"\"\"\n",
    "    Mask a ratio of items in the sequence by replacing them with a special token (e.g., 0).\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence: list of int, 아이템 인덱스 시퀀스.\n",
    "    - mask_ratio: float, 마스킹 비율 (기본값: 0.2).\n",
    "    - mask_token: int, 마스킹에 사용할 토큰 (기본값: 0).\n",
    "    \n",
    "    Returns:\n",
    "    - sequence: list of int, 마스킹된 시퀀스.\n",
    "    \"\"\"\n",
    "    sequence = sequence.copy()\n",
    "    num_to_mask = max(1, int(len(sequence) * mask_ratio))\n",
    "    mask_indices = np.random.choice(len(sequence), num_to_mask, replace=False)\n",
    "    for idx in mask_indices:\n",
    "        sequence[idx] = mask_token  # Assuming 0 is the padding/masking index\n",
    "    return sequence\n",
    "\n",
    "def reorder(sequence, reorder_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Reorder a ratio of items in the sequence by shuffling them.\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence: list of int, 아이템 인덱스 시퀀스.\n",
    "    - reorder_ratio: float, 재배열 비율 (기본값: 0.2).\n",
    "    \n",
    "    Returns:\n",
    "    - sequence: list of int, 재배열된 시퀀스.\n",
    "    \"\"\"\n",
    "    sequence = sequence.copy()\n",
    "    num_to_reorder = max(1, int(len(sequence) * reorder_ratio))\n",
    "    reorder_indices = np.random.choice(len(sequence), num_to_reorder, replace=False)\n",
    "    reordered_items = [sequence[idx] for idx in reorder_indices]\n",
    "    np.random.shuffle(reordered_items)\n",
    "    for i, idx in enumerate(reorder_indices):\n",
    "        sequence[idx] = reordered_items[i]\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialDataset(Dataset):\n",
    "    def __init__(self, train_matrix: csr_matrix, validation_matrix: csr_matrix, max_seq_length: int = 50, augmentations: list = None):\n",
    "        \"\"\"\n",
    "        사용자-아이템 상호작용 행렬을 기반으로 시퀀스를 생성하고, 데이터 증강을 적용합니다.\n",
    "\n",
    "        Parameters:\n",
    "        - train_matrix: csr_matrix, 훈련 데이터 상호작용 행렬.\n",
    "        - validation_matrix: csr_matrix, 검증 데이터 상호작용 행렬.\n",
    "        - max_seq_length: int, 최대 시퀀스 길이.\n",
    "        - augmentations: list of functions, 데이터 증강 함수 리스트.\n",
    "        \"\"\"\n",
    "        self.train_matrix = train_matrix\n",
    "        self.validation_matrix = validation_matrix\n",
    "        self.num_users, self.num_items = train_matrix.shape\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.augmentations = augmentations if augmentations is not None else []\n",
    "\n",
    "        # Preprocess: create a list of (user, target) pairs\n",
    "        self.samples = []\n",
    "        for user in range(self.num_users):\n",
    "            train_item_indices = set(train_matrix[user].indices)\n",
    "            val_item_indices = validation_matrix[user].indices\n",
    "            if len(val_item_indices) == 0:\n",
    "                continue  # Skip users with no validation items\n",
    "            for target in val_item_indices:\n",
    "                # Define the training sequence as all train items for the user\n",
    "                sequence = list(train_item_indices)\n",
    "                self.samples.append((user, sequence, target))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user, sequence, target = self.samples[idx]\n",
    "\n",
    "        # Pad or truncate the sequence to max_seq_length\n",
    "        if len(sequence) > self.max_seq_length:\n",
    "            sequence_padded = sequence[-self.max_seq_length:]\n",
    "        else:\n",
    "            sequence_padded = [0] * (self.max_seq_length - len(sequence)) + sequence  # Assuming 0 is the padding index\n",
    "\n",
    "        # Apply augmentations to create two views\n",
    "        if len(self.augmentations) >= 2:\n",
    "            a1, a2 = random.sample(self.augmentations, 2)\n",
    "            augmented_seq1 = a1(sequence_padded)\n",
    "            augmented_seq2 = a2(sequence_padded)\n",
    "        elif len(self.augmentations) == 1:\n",
    "            a1 = self.augmentations[0]\n",
    "            augmented_seq1 = a1(sequence_padded)\n",
    "            augmented_seq2 = a1(sequence_padded)\n",
    "        else:\n",
    "            augmented_seq1 = sequence_padded\n",
    "            augmented_seq2 = sequence_padded\n",
    "\n",
    "        # Ensure augmented sequences are of fixed length\n",
    "        if len(augmented_seq1) > self.max_seq_length:\n",
    "            augmented_seq1 = augmented_seq1[-self.max_seq_length:]\n",
    "        elif len(augmented_seq1) < self.max_seq_length:\n",
    "            augmented_seq1 = [0] * (self.max_seq_length - len(augmented_seq1)) + augmented_seq1\n",
    "\n",
    "        if len(augmented_seq2) > self.max_seq_length:\n",
    "            augmented_seq2 = augmented_seq2[-self.max_seq_length:]\n",
    "        elif len(augmented_seq2) < self.max_seq_length:\n",
    "            augmented_seq2 = [0] * (self.max_seq_length - len(augmented_seq2)) + augmented_seq2\n",
    "\n",
    "        return {\n",
    "            'seq1': torch.tensor(augmented_seq1, dtype=torch.long),\n",
    "            'seq2': torch.tensor(augmented_seq2, dtype=torch.long),\n",
    "            'target': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CL4SRecModel(nn.Module):\n",
    "    def __init__(self, num_items, embed_dim=128, num_heads=4, num_layers=2, dropout=0.1):\n",
    "        \"\"\"\n",
    "        CL4SRec 모델 정의.\n",
    "        \n",
    "        Parameters:\n",
    "        - num_items: int, 아이템의 총 개수.\n",
    "        - embed_dim: int, 임베딩 차원.\n",
    "        - num_heads: int, Transformer의 헤드 수.\n",
    "        - num_layers: int, Transformer 인코더 레이어 수.\n",
    "        - dropout: float, 드롭아웃 비율.\n",
    "        \"\"\"\n",
    "        super(CL4SRecModel, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Item embedding (0은 패딩 인덱스)\n",
    "        self.item_embedding = nn.Embedding(num_items + 1, embed_dim, padding_idx=0)\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Prediction layer for next item prediction\n",
    "        self.predictor = nn.Linear(embed_dim, num_items +1)\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        \"\"\"\n",
    "        순전파 함수.\n",
    "        \n",
    "        Parameters:\n",
    "        - sequences: tensor of shape (batch_size, seq_length)\n",
    "        \n",
    "        Returns:\n",
    "        - logits: tensor of shape (batch_size, num_items +1)\n",
    "        - encoded: tensor of shape (batch_size, embed_dim)\n",
    "        \"\"\"\n",
    "        # Embed the sequences\n",
    "        embedded = self.item_embedding(sequences)  # (batch_size, seq_length, embed_dim)\n",
    "\n",
    "        # Transformer expects input of shape (seq_length, batch_size, embed_dim)\n",
    "        embedded = embedded.transpose(0, 1)\n",
    "\n",
    "        # Pass through Transformer encoder\n",
    "        encoded = self.transformer_encoder(embedded)  # (seq_length, batch_size, embed_dim)\n",
    "\n",
    "        # Take the representation of the last time step\n",
    "        encoded = encoded[-1, :, :]  # (batch_size, embed_dim)\n",
    "\n",
    "        # Predict the next item\n",
    "        logits = self.predictor(encoded)  # (batch_size, num_items +1)\n",
    "\n",
    "        return logits, encoded  # Return both logits and encoded representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(encoded1, encoded2, temperature=0.07):\n",
    "    \"\"\"\n",
    "    두 인코딩된 시퀀스 간의 대조 손실을 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoded1: tensor of shape (batch_size, embed_dim)\n",
    "    - encoded2: tensor of shape (batch_size, embed_dim)\n",
    "    - temperature: float, 스케일링을 위한 온도 파라미터\n",
    "    \n",
    "    Returns:\n",
    "    - loss: tensor, 대조 손실 값\n",
    "    \"\"\"\n",
    "    batch_size = encoded1.size(0)\n",
    "    \n",
    "    # 임베딩 정규화\n",
    "    encoded1 = nn.functional.normalize(encoded1, dim=1)\n",
    "    encoded2 = nn.functional.normalize(encoded2, dim=1)\n",
    "\n",
    "    # 유사도 매트릭스 계산\n",
    "    logits = torch.matmul(encoded1, encoded2.T) / temperature  # (batch_size, batch_size)\n",
    "\n",
    "    # 정답 레이블 생성 (대각선 위치가 정답)\n",
    "    labels = torch.arange(batch_size).to(encoded1.device)\n",
    "\n",
    "    # 교차 엔트로피 손실 계산\n",
    "    loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "Seq1 length: 50, Seq2 length: 50, Target: 34\n",
      "Seq1: tensor([326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 370, 361, 346, 347, 348, 371, 350, 351, 352, 349,\n",
      "        354, 355, 356, 359, 358, 345, 360, 344, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 357, 353, 372, 373, 374, 375])\n",
      "Seq2: tensor([326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375])\n",
      "\n",
      "Sample 1:\n",
      "Seq1 length: 50, Seq2 length: 50, Target: 168\n",
      "Seq1: tensor([326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375])\n",
      "Seq2: tensor([  0,   0, 328, 329, 330, 331, 332, 333, 334,   0, 336, 337,   0, 339,\n",
      "        340,   0, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358,   0, 360,   0, 362, 363, 364, 365, 366,   0,\n",
      "          0,   0, 370, 371, 372, 373, 374, 375])\n",
      "\n",
      "Sample 2:\n",
      "Seq1 length: 50, Seq2 length: 50, Target: 376\n",
      "Seq1: tensor([326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375])\n",
      "Seq2: tensor([326, 370, 328, 329, 330, 331, 332, 327, 334, 335, 336, 337, 338, 339,\n",
      "        369, 341, 342, 343, 333, 345, 346, 347, 360, 349, 350, 351, 352, 353,\n",
      "        348, 355, 356, 357, 358, 359, 354, 340, 362, 363, 364, 365, 366, 367,\n",
      "        368, 344, 361, 371, 372, 373, 374, 375])\n",
      "\n",
      "Sample 3:\n",
      "Seq1 length: 50, Seq2 length: 50, Target: 150\n",
      "Seq1: tensor([462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "Seq2: tensor([462, 463, 464, 465, 466, 494, 485, 469, 468, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 489, 487, 483, 484, 482, 486, 481, 488, 470,\n",
      "        490, 491, 492, 493, 467, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n",
      "Sample 4:\n",
      "Seq1 length: 50, Seq2 length: 50, Target: 276\n",
      "Seq1: tensor([462, 463, 464, 465, 466, 481, 468, 492, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 467, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 496, 493, 494, 501, 495, 497, 498, 499, 500, 507, 502, 503,\n",
      "        504, 505, 506, 469, 508, 509, 510, 511])\n",
      "Seq2: tensor([462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 증강 리스트\n",
    "augmentations = [crop, mask, reorder]\n",
    "\n",
    "# Dataset 및 DataLoader 생성\n",
    "train_dataset = SequentialDataset(train_matrix, validation_matrix, max_seq_length=50, augmentations=augmentations)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "\n",
    "# 데이터셋 일부를 확인하여 시퀀스 길이가 올바른지 확인\n",
    "for i in range(5):\n",
    "    sample = train_dataset[i]\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"Seq1 length: {len(sample['seq1'])}, Seq2 length: {len(sample['seq2'])}, Target: {sample['target']}\")\n",
    "    print(f\"Seq1: {sample['seq1']}\")\n",
    "    print(f\"Seq2: {sample['seq2']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch, temperature=0.07):\n",
    "    \"\"\"\n",
    "    모델을 학습하는 함수.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: nn.Module, 학습할 모델.\n",
    "    - train_loader: DataLoader, 학습 데이터로더.\n",
    "    - optimizer: torch.optim.Optimizer, 옵티마이저.\n",
    "    - epoch: int, 현재 에폭 번호.\n",
    "    - temperature: float, 대조 손실 계산을 위한 온도 파라미터.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        seq1 = batch['seq1'].to(device)  # (batch_size, seq_length)\n",
    "        seq2 = batch['seq2'].to(device)  # (batch_size, seq_length)\n",
    "        targets = batch['target'].to(device)  # (batch_size)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # seq1에 대한 순전파\n",
    "        logits1, encoded1 = model(seq1)  # logits1: (batch_size, num_items +1), encoded1: (batch_size, embed_dim)\n",
    "\n",
    "        # seq2에 대한 순전파\n",
    "        logits2, encoded2 = model(seq2)  # logits2: (batch_size, num_items +1), encoded2: (batch_size, embed_dim)\n",
    "\n",
    "        # 다음 아이템 예측 손실\n",
    "        loss_pred1 = nn.functional.cross_entropy(logits1, targets)\n",
    "        loss_pred2 = nn.functional.cross_entropy(logits2, targets)\n",
    "        loss_pred = (loss_pred1 + loss_pred2) / 2\n",
    "\n",
    "        # 대조 손실\n",
    "        loss_contrast = (contrastive_loss(encoded1, encoded2, temperature) + \n",
    "                         contrastive_loss(encoded2, encoded1, temperature)) / 2\n",
    "\n",
    "        # 총 손실\n",
    "        loss = loss_pred + loss_contrast\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, validation_matrix, train_matrix, k=10):\n",
    "    \"\"\"\n",
    "    모델을 평가하는 함수.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: nn.Module, 학습된 모델.\n",
    "    - validation_matrix: csr_matrix, 검증 데이터 상호작용 행렬.\n",
    "    - train_matrix: csr_matrix, 훈련 데이터 상호작용 행렬.\n",
    "    - k: int, 컷오프 값.\n",
    "    \n",
    "    Returns:\n",
    "    - mean_recall: float, 평균 Recall@k.\n",
    "    - mean_ndcg: float, 평균 NDCG@k.\n",
    "    - mean_loss: float, 평균 Validation Loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    all_recall = []\n",
    "    all_ndcg = []\n",
    "    batch_size = 256\n",
    "    num_users = validation_matrix.shape[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for start in tqdm(range(0, num_users, batch_size), desc=\"Evaluating\"):\n",
    "            end = min(start + batch_size, num_users)\n",
    "            users = np.arange(start, end)\n",
    "            \n",
    "            # 시퀀스 및 타겟 준비\n",
    "            sequences = []\n",
    "            val_targets = []\n",
    "            for user in users:\n",
    "                train_items = train_matrix[user].indices\n",
    "                if len(train_items) > 0:\n",
    "                    seq = train_items[-50:].tolist()\n",
    "                else:\n",
    "                    seq = []\n",
    "                if len(seq) < 50:\n",
    "                    seq = [0] * (50 - len(seq)) + seq  # 패딩\n",
    "                sequences.append(seq)\n",
    "                \n",
    "                # 각 사용자에 대해 하나의 타겟만 선택 (예: 마지막 아이템)\n",
    "                val_items = validation_matrix[user].indices\n",
    "                if len(val_items) > 0:\n",
    "                    val_targets.append(val_items[-1])  # 마지막 아이템을 타겟으로 사용\n",
    "                else:\n",
    "                    val_targets.append(0)  # 타겟이 없는 경우 0으로 패딩 (패딩 인덱스와 일치해야 함)\n",
    "            \n",
    "            if len(sequences) == 0:\n",
    "                continue  # 검증 세트에 아이템이 없는 사용자 스킵\n",
    "            \n",
    "            sequences = torch.tensor(sequences, dtype=torch.long).to(device)  # (batch_size, seq_length)\n",
    "            targets_tensor = torch.tensor(val_targets, dtype=torch.long).to(device)  # (batch_size)\n",
    "            \n",
    "            # 모델 예측\n",
    "            logits, _ = model(sequences)  # logits: (batch_size, num_items +1)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss_pred = loss_fn(logits, targets_tensor)\n",
    "            total_loss += loss_pred.item() * len(users)\n",
    "            total_samples += len(users)\n",
    "            \n",
    "            # 예측 점수 추출\n",
    "            X_pred = logits.cpu().numpy()\n",
    "            \n",
    "            # 실제 타겟 이진 행렬 생성 (Recall@k, NDCG@k 계산을 위해)\n",
    "            heldout_batch = validation_matrix[users].toarray()\n",
    "            \n",
    "            # Recall@k 및 NDCG@k 계산\n",
    "            recall = Recall_at_k_batch(X_pred, heldout_batch, k)\n",
    "            ndcg = NDCG_binary_at_k_batch(X_pred, heldout_batch, k)\n",
    "            all_recall.extend(recall)\n",
    "            all_ndcg.extend(ndcg)\n",
    "    \n",
    "    mean_recall = np.mean(all_recall) if all_recall else 0.0\n",
    "    mean_ndcg = np.mean(all_ndcg) if all_ndcg else 0.0\n",
    "    mean_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "    \n",
    "    print(f\"Validation Loss: {mean_loss:.4f}, Recall@{k}: {mean_recall:.4f}, NDCG@{k}: {mean_ndcg:.4f}\")\n",
    "    return mean_recall, mean_ndcg, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/368 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 368/368 [00:39<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 9.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.4970, Recall@10: 0.0257, NDCG@10: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 8.1888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.3358, Recall@10: 0.0337, NDCG@10: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 7.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.1681, Recall@10: 0.0378, NDCG@10: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 7.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 8.0235, Recall@10: 0.0430, NDCG@10: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 7.5139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.8706, Recall@10: 0.0476, NDCG@10: 0.0332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 7.3638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.7258, Recall@10: 0.0513, NDCG@10: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 7.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.6347, Recall@10: 0.0534, NDCG@10: 0.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 7.0993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.5544, Recall@10: 0.0591, NDCG@10: 0.0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 6.9797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.4580, Recall@10: 0.0619, NDCG@10: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 6.8617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.3624, Recall@10: 0.0653, NDCG@10: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 6.7470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.2746, Recall@10: 0.0698, NDCG@10: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 6.6294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.2263, Recall@10: 0.0719, NDCG@10: 0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 6.5138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.1689, Recall@10: 0.0758, NDCG@10: 0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 6.3940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.1196, Recall@10: 0.0799, NDCG@10: 0.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 6.2743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.0754, Recall@10: 0.0827, NDCG@10: 0.0608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 6.1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.0326, Recall@10: 0.0882, NDCG@10: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 6.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.9682, Recall@10: 0.0930, NDCG@10: 0.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 5.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.9439, Recall@10: 0.0950, NDCG@10: 0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 368/368 [00:39<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 5.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.9230, Recall@10: 0.0996, NDCG@10: 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 5.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.8687, Recall@10: 0.1041, NDCG@10: 0.0787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 5.5154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.8387, Recall@10: 0.1076, NDCG@10: 0.0816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 5.3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.8089, Recall@10: 0.1131, NDCG@10: 0.0860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 368/368 [00:39<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 5.2512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.7838, Recall@10: 0.1157, NDCG@10: 0.0883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 5.1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.7240, Recall@10: 0.1211, NDCG@10: 0.0932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 4.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6997, Recall@10: 0.1256, NDCG@10: 0.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 4.8678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.7089, Recall@10: 0.1278, NDCG@10: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 4.7457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6523, Recall@10: 0.1339, NDCG@10: 0.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 368/368 [00:39<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 4.6226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6823, Recall@10: 0.1359, NDCG@10: 0.1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 4.5018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6463, Recall@10: 0.1394, NDCG@10: 0.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 4.3847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6353, Recall@10: 0.1440, NDCG@10: 0.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 4.2754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5751, Recall@10: 0.1492, NDCG@10: 0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 4.1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6244, Recall@10: 0.1500, NDCG@10: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 4.0605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5935, Recall@10: 0.1526, NDCG@10: 0.1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 3.9603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6041, Recall@10: 0.1549, NDCG@10: 0.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 3.8662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6290, Recall@10: 0.1595, NDCG@10: 0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 368/368 [00:39<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 3.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5511, Recall@10: 0.1656, NDCG@10: 0.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 3.6869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5527, Recall@10: 0.1677, NDCG@10: 0.1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 368/368 [00:39<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 3.6002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5422, Recall@10: 0.1716, NDCG@10: 0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 3.5237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5770, Recall@10: 0.1710, NDCG@10: 0.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 3.4514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5359, Recall@10: 0.1764, NDCG@10: 0.1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 368/368 [00:39<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 3.3827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5509, Recall@10: 0.1797, NDCG@10: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 3.3149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5093, Recall@10: 0.1849, NDCG@10: 0.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 3.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5176, Recall@10: 0.1860, NDCG@10: 0.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 3.1959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5596, Recall@10: 0.1874, NDCG@10: 0.1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 3.1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5400, Recall@10: 0.1889, NDCG@10: 0.1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 3.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5195, Recall@10: 0.1923, NDCG@10: 0.1534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 3.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5047, Recall@10: 0.1966, NDCG@10: 0.1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 2.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5483, Recall@10: 0.1962, NDCG@10: 0.1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 2.9550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5039, Recall@10: 0.2016, NDCG@10: 0.1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 2.9184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5157, Recall@10: 0.2021, NDCG@10: 0.1628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Loss: 2.8717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5251, Recall@10: 0.2064, NDCG@10: 0.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Loss: 2.8432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.5265, Recall@10: 0.2069, NDCG@10: 0.1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Loss: 2.8127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.4553, Recall@10: 0.2119, NDCG@10: 0.1715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 368/368 [00:39<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Loss: 2.7811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.4096, Recall@10: 0.2136, NDCG@10: 0.1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 368/368 [00:38<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Loss: 2.7490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.4580, Recall@10: 0.2179, NDCG@10: 0.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 368/368 [00:39<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Loss: 2.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.4349, Recall@10: 0.2183, NDCG@10: 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 368/368 [00:39<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Loss: 2.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.4739, Recall@10: 0.2204, NDCG@10: 0.1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 368/368 [00:39<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Loss: 2.6790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.4271, Recall@10: 0.2242, NDCG@10: 0.1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 368/368 [00:39<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Loss: 2.6546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.4522, Recall@10: 0.2247, NDCG@10: 0.1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 368/368 [00:39<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss: 2.6307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 123/123 [00:13<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.3972, Recall@10: 0.2290, NDCG@10: 0.1873\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "model = CL4SRecModel(num_items=num_items, embed_dim=256, num_heads=8, num_layers=4, dropout=0.1)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 옵티마이저 및 스케줄러 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# Early Stopping을 위한 변수 초기화\n",
    "best_loss = float('inf')\n",
    "patience = 7  # patience 값을 늘려 조기 중단을 지연시킴\n",
    "counter = 0\n",
    "\n",
    "# 모델 학습 및 평가 루프\n",
    "num_epochs = 60\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    recall, ndcg, val_loss = evaluate(model, validation_matrix, train_matrix, k=10)\n",
    "    # Early Stopping 체크\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        counter = 0\n",
    "        # 최적 모델 저장\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출 파일 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 및 아이템 ID 매핑 딕셔너리 생성\n",
    "idx2usr_dict = {v: k for k, v in usr2idx_dict.items()}\n",
    "idx2item_dict = {v: k for k, v in item2idx_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_recommendations(model, train_matrix, idx2usr_dict, idx2item_dict, top_k=10, device='cpu'):\n",
    "    \"\"\"\n",
    "    Generate top-k recommendations for each user after masking existing interactions and excluding padding.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained PyTorch model.\n",
    "    - train_matrix: csr_matrix, training data interaction matrix.\n",
    "    - idx2usr_dict: dict, mapping from internal user indices to original user IDs.\n",
    "    - idx2item_dict: dict, mapping from internal item indices to original item IDs.\n",
    "    - top_k: int, number of recommendations to generate per user.\n",
    "    - device: str, device to perform computations ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - recommendations_df: pd.DataFrame, user-to-top-k recommended items with one item per row.\n",
    "    \"\"\"\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    num_users = train_matrix.shape[0]\n",
    "    num_items = train_matrix.shape[1]\n",
    "    \n",
    "    recommendations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user_idx in tqdm(range(num_users), desc=\"Generating Recommendations\"):\n",
    "            # 사용자의 상호작용 아이템 가져오기\n",
    "            train_items = set(train_matrix[user_idx].indices)\n",
    "            \n",
    "            # 시퀀스 준비: 마지막 50개 아이템, 패딩은 0\n",
    "            seq = list(train_items)[-50:] if len(train_items) >= 50 else list(train_items)\n",
    "            if len(seq) < 50:\n",
    "                seq = [0] * (50 - len(seq)) + seq  # 패딩\n",
    "            elif len(seq) > 50:\n",
    "                seq = seq[-50:]\n",
    "            \n",
    "            # 시퀀스를 텐서로 변환하고 디바이스로 이동\n",
    "            seq_tensor = torch.tensor([seq], dtype=torch.long).to(device)  # Shape: (1, 50)\n",
    "            \n",
    "            # 모델을 통해 예측 점수 계산\n",
    "            logits, _ = model(seq_tensor)  # logits: (1, num_items +1)\n",
    "            scores = logits.cpu().numpy()[0]  # Shape: (num_items +1,)\n",
    "            \n",
    "            # 마스킹: 이미 상호작용한 아이템과 패딩 인덱스 `0` 제외\n",
    "            scores[list(train_items)] = -np.inf\n",
    "            scores[0] = -np.inf  # 패딩 인덱스 제외\n",
    "            \n",
    "            # 상위 k개 아이템 선택\n",
    "            top_items = np.argsort(-scores)[:top_k]\n",
    "            \n",
    "            # 추천 아이템 매핑 및 필터링\n",
    "            recommended_items = [idx2item_dict.get(item_idx, 0) for item_idx in top_items \n",
    "                                 if item_idx != 0 and item_idx not in train_items]\n",
    "            \n",
    "            # 추천 아이템이 부족할 경우, 랜덤 아이템 추가\n",
    "            if len(recommended_items) < top_k:\n",
    "                available_items = set(range(1, num_items +1)) - train_items - set(top_items)\n",
    "                if available_items:\n",
    "                    remaining = top_k - len(recommended_items)\n",
    "                    additional_items = np.random.choice(list(available_items), size=remaining, replace=False)\n",
    "                    recommended_items += [idx2item_dict.get(item, 0) for item in additional_items]\n",
    "            \n",
    "            # 추천 아이템이 정확히 top_k개인지 확인\n",
    "            recommended_items = recommended_items[:top_k]\n",
    "            while len(recommended_items) < top_k:\n",
    "                # 추가 아이템이 없을 경우, 다른 전략을 적용할 수 있습니다.\n",
    "                # 여기서는 임의로 0을 추가하지만, 실제로는 다른 아이템으로 대체하는 것이 좋습니다.\n",
    "                recommended_items.append(0)\n",
    "            \n",
    "            # 사용자 ID 매핑\n",
    "            original_user_id = idx2usr_dict.get(user_idx, user_idx)\n",
    "            \n",
    "            # 추천 아이템을 개별 행으로 추가\n",
    "            for item in recommended_items:\n",
    "                if item != 0:  # 0이 아닌 경우에만 추가\n",
    "                    recommendations.append({'user': original_user_id, 'item': item})\n",
    "    \n",
    "    # DataFrame 생성\n",
    "    recommendations_df = pd.DataFrame(recommendations)\n",
    "    \n",
    "    # CSV 파일로 저장\n",
    "    recommendations_df.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file saved as 'submission.csv'\")\n",
    "    \n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Recommendations:   0%|          | 0/31360 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Recommendations: 100%|██████████| 31360/31360 [01:39<00:00, 314.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as 'submission.csv'\n",
      "   user   item\n",
      "0    11    173\n",
      "1    11     19\n",
      "2    11   4226\n",
      "3    11  68941\n",
      "4    11   8830\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델 로드\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 추천 생성 함수 호출\n",
    "recommendations_df = generate_recommendations(model, train_matrix, idx2usr_dict, idx2item_dict, top_k=10, device=device)\n",
    "\n",
    "# 추천 결과 확인\n",
    "print(recommendations_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
