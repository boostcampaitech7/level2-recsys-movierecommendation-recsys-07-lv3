{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "oO5VjOHlI1QN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader,Sampler\n",
    "from torch.sparse import mm\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import argparse\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyeNFpnDI1QO",
    "outputId": "9986bcb6-5457-41f1-860f-c784e2c0a42b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4f7a55fcf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMoH3grBI2vO",
    "outputId": "52e0d5d1-c70c-4f69-b8b4-8b4a84b82f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-15 14:04:40--  https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000339/data/data.tar.gz\n",
      "Resolving aistages-api-public-prod.s3.amazonaws.com (aistages-api-public-prod.s3.amazonaws.com)... 52.219.202.15, 3.5.186.37, 52.219.146.2, ...\n",
      "Connecting to aistages-api-public-prod.s3.amazonaws.com (aistages-api-public-prod.s3.amazonaws.com)|52.219.202.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33425907 (32M) [binary/octet-stream]\n",
      "Saving to: ‘data.tar.gz’\n",
      "\n",
      "data.tar.gz         100%[===================>]  31.88M  9.53MB/s    in 3.3s    \n",
      "\n",
      "2024-11-15 14:04:45 (9.53 MB/s) - ‘data.tar.gz’ saved [33425907/33425907]\n",
      "\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.dropbox.attrs'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.dropbox.attrs'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.dropbox.attrs'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.dropbox.attrs'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n"
     ]
    }
   ],
   "source": [
    "!wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000339/data/data.tar.gz\n",
    "!tar -xf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "NV5JnoiTOilm"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--wd', type=float, default=0.00,\n",
    "                    help='weight decay coefficient')\n",
    "parser.add_argument('--batch_size', type=int, default=500,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=20,\n",
    "                    help='upper epoch limit')\n",
    "parser.add_argument('--total_anneal_steps', type=int, default=200000,\n",
    "                    help='the total number of gradient updates for annealing')\n",
    "parser.add_argument('--anneal_cap', type=float, default=0.2,\n",
    "                    help='largest annealing parameter')\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='use CUDA')\n",
    "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n",
    "                    help='report interval')\n",
    "parser.add_argument('--save', type=str, default='model.pt',\n",
    "                    help='path to save the final model')\n",
    "args = parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsxTa9drI1QP"
   },
   "source": [
    "### 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z-9FX9aJI1QP"
   },
   "outputs": [],
   "source": [
    "data_path = ('data/')\n",
    "train_df = pd.read_csv(os.path.join(data_path, 'train/train_ratings.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba2PtHyTI1QQ"
   },
   "source": [
    "### 기본적인 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msLXvAGKI1QQ",
    "outputId": "70dce0d3-7776-49a1-aeef-2b4c244da4d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5154471, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "h5DWqCqYI1QQ",
    "outputId": "0e55d43b-e515-4e65-c46c-9a6fa7bcd467"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-2ce34504-ae3c-420a-a79c-507f945c7f50\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1230782534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1230782539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1230782542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1230782563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ce34504-ae3c-420a-a79c-507f945c7f50')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2ce34504-ae3c-420a-a79c-507f945c7f50 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2ce34504-ae3c-420a-a79c-507f945c7f50');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-0b41df35-def8-430b-9e1c-a62d5fe8c44a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b41df35-def8-430b-9e1c-a62d5fe8c44a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-0b41df35-def8-430b-9e1c-a62d5fe8c44a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   user  item        time\n",
       "0    11  4643  1230782529\n",
       "1    11   170  1230782534\n",
       "2    11   531  1230782539\n",
       "3    11   616  1230782542\n",
       "4    11  2140  1230782563"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "3vav2bM8I1QQ",
    "outputId": "e10f4cff-e2b2-4717-9871-4c9638fe536f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "user    0\n",
       "item    0\n",
       "time    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKuZ87UfI1QR",
    "outputId": "9a23bdde-61e1-457d-a9e3-38fdb5639c76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31360"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['user'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIObMei_I1QR",
    "outputId": "ba8c938a-1868-425e-859a-3a34bf3be0b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6807"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['item'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHNDrpNEI1QR"
   },
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7kKRRe-I1QR"
   },
   "source": [
    "ALS 에 input으로 넣어줄 수 있게 csr matrix 형태로 바꿔줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SEKb1K3EI1QR"
   },
   "outputs": [],
   "source": [
    "# reindexing function\n",
    "\n",
    "def reindex_column(data, column_name):\n",
    "    \"\"\"\n",
    "    Reindex a column in the dataframe to ensure continuous indices starting from 0.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pd.DataFrame, the input dataframe.\n",
    "    - column_name: str, the column to reindex.\n",
    "\n",
    "    Returns:\n",
    "    - data: pd.DataFrame, the dataframe with reindexed column.\n",
    "    - mapping_dict: dict, the original-to-new mapping dictionary.\n",
    "    \"\"\"\n",
    "    # Create the mapping dictionary\n",
    "    mapping_dict = {original_id: new_id for new_id, original_id in enumerate(data[column_name].unique())}\n",
    "\n",
    "    # Apply the mapping to the dataframe\n",
    "    data[column_name] = data[column_name].map(mapping_dict)\n",
    "\n",
    "    return data, mapping_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "p4AonX7QI1QR"
   },
   "outputs": [],
   "source": [
    "# index 조정\n",
    "original_df = train_df.copy()\n",
    "train_df,usr2idx_dict = reindex_column(train_df,'user')\n",
    "train_df,item2idx_dict = reindex_column(train_df,'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "j2bzLxwXI1QS"
   },
   "outputs": [],
   "source": [
    "# csr 구성하는 row column define\n",
    "row,column = train_df['user'],train_df['item']\n",
    "feedback = np.ones_like(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "rA2FYUF4I1QS"
   },
   "outputs": [],
   "source": [
    "# csr matrix 생성\n",
    "num_users,num_items = train_df['user'].nunique(),train_df['item'].nunique()\n",
    "\n",
    "interaction_matrix = csr_matrix((feedback,(row,column)),dtype = 'float64',shape = (num_users,num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSNw9O4ARGzQ",
    "outputId": "2ead96fb-33ff-44f3-c534-12dcf60e43ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31360x6807 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5154471 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU-azis_I1QT"
   },
   "source": [
    "Train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZehVBQcPI1QT"
   },
   "outputs": [],
   "source": [
    "def train_validation_split(interaction_matrix, valid_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split a CSR interaction matrix into training and validation sets with specific rules:\n",
    "    - If valid_ratio == 0, all interactions are included in the training set.\n",
    "    - Otherwise:\n",
    "        - Last interaction is always included in the validation set.\n",
    "        - Additional interactions are randomly selected (if available).\n",
    "        - Validation set size is capped at valid_ratio of the user's total interactions.\n",
    "\n",
    "    Parameters:\n",
    "    - interaction_matrix: csr_matrix, the full user-item interaction matrix.\n",
    "    - valid_ratio: float, fraction of interactions to include in the validation set.\n",
    "\n",
    "    Returns:\n",
    "    - train_matrix: csr_matrix, training set interactions.\n",
    "    - validation_matrix: csr_matrix, validation set interactions.\n",
    "    \"\"\"\n",
    "    if valid_ratio == 0:\n",
    "        # Use the entire matrix as the training set and return an empty validation set\n",
    "        train_matrix = interaction_matrix.copy()\n",
    "        return train_matrix\n",
    "\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    val_rows, val_cols, val_data = [], [], []\n",
    "\n",
    "    # Iterate over each user in the interaction matrix\n",
    "    for user in range(interaction_matrix.shape[0]):\n",
    "        # Get the non-zero interactions (item indices) for this user\n",
    "        item_indices = interaction_matrix[user].nonzero()[1]\n",
    "        num_items = len(item_indices)\n",
    "\n",
    "        if num_items == 0:\n",
    "            continue  # Skip users with no interactions\n",
    "\n",
    "        # Determine the maximum validation set size (at least 1 item)\n",
    "        max_val_items = max(1, int(valid_ratio * num_items))\n",
    "\n",
    "        # Last interaction is always included in the validation set\n",
    "        val_items = [item_indices[-1]]\n",
    "\n",
    "        # Randomly sample additional items from the remaining interactions\n",
    "        remaining_items = item_indices[:-1]\n",
    "        if len(remaining_items) > 0:\n",
    "            num_random_items = min(max_val_items - 1, len(remaining_items))\n",
    "            random_items = np.random.choice(remaining_items, size=num_random_items, replace=False)\n",
    "            val_items.extend(random_items)\n",
    "\n",
    "        # Add the remaining items to the training set\n",
    "        train_items = list(set(item_indices) - set(val_items))\n",
    "\n",
    "        # Add training interactions\n",
    "        train_rows.extend([user] * len(train_items))\n",
    "        train_cols.extend(train_items)\n",
    "        train_data.extend([1] * len(train_items))\n",
    "\n",
    "        # Add validation interactions\n",
    "        val_rows.extend([user] * len(val_items))\n",
    "        val_cols.extend(val_items)\n",
    "        val_data.extend([1] * len(val_items))\n",
    "\n",
    "    # Create CSR matrices for training and validation\n",
    "    train_matrix = csr_matrix((train_data, (train_rows, train_cols)), dtype='float64', shape=interaction_matrix.shape)\n",
    "    validation_matrix = csr_matrix((val_data, (val_rows, val_cols)), dtype='float64', shape=interaction_matrix.shape)\n",
    "\n",
    "    return train_matrix, validation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "4QmID6BnI1QU"
   },
   "outputs": [],
   "source": [
    "train_data,val_data = train_validation_split(interaction_matrix,valid_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yy5tT6snQ41A",
    "outputId": "8f60a7ff-4366-4e9f-d8e4-a5d9152a391b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31360x6807 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 94080 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1m-Xl9XI1QV"
   },
   "source": [
    "### 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aAURLE0MI1QV"
   },
   "outputs": [],
   "source": [
    "class MultiVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-VAE.\n",
    "\n",
    "    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims:\n",
    "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        else:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "\n",
    "        # Last dimension of q- network is for mean and variance\n",
    "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
    "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
    "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.encode(input)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def encode(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                mu = h[:, :self.q_dims[-1]]\n",
    "                logvar = h[:, self.q_dims[-1]:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.q_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "\n",
    "        for layer in self.p_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8agVvbM3I1QW"
   },
   "source": [
    "### Loss funtion 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JoIOiSnGI1QW"
   },
   "outputs": [],
   "source": [
    "def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n",
    "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "\n",
    "    return BCE + anneal * KLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiEkiQgKI1QW"
   },
   "source": [
    "Train 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "FDAh67tQM1nf"
   },
   "outputs": [],
   "source": [
    "def naive_sparse2tensor(data):\n",
    "    return torch.FloatTensor(data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "ZGfTAeuqI1QW"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_data, device, args, is_VAE=True):\n",
    "    \"\"\"\n",
    "    Train the model on the given training data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: PyTorch model\n",
    "    - criterion: Loss function\n",
    "    - optimizer: Optimizer for training\n",
    "    - train_data: csr_matrix, training data\n",
    "    - device: PyTorch device (e.g., 'cuda' or 'cpu')\n",
    "    - args: Arguments containing hyperparameters\n",
    "    - is_VAE: Whether the model is a VAE (default: True)\n",
    "\n",
    "    Returns:\n",
    "    - train_loss: Average training loss over all batches\n",
    "    \"\"\"\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    global update_count\n",
    "\n",
    "    for batch_idx, start_idx in enumerate(range(0, train_data.shape[0], args.batch_size)):\n",
    "        end_idx = min(start_idx + args.batch_size, train_data.shape[0])\n",
    "        data = train_data[start_idx:end_idx]\n",
    "        data = naive_sparse2tensor(data).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if is_VAE:\n",
    "            if args.total_anneal_steps > 0:\n",
    "                anneal = min(args.anneal_cap, 1. * update_count / args.total_anneal_steps)\n",
    "            else:\n",
    "                anneal = args.anneal_cap\n",
    "\n",
    "        # Forward pass and loss computation\n",
    "        if is_VAE:\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_function_vae(recon_batch, data, mu, logvar, anneal)\n",
    "        else:\n",
    "            recon_batch = model(data)\n",
    "            loss = criterion(recon_batch, data)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        update_count += 1\n",
    "\n",
    "        # Log progress\n",
    "        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
    "                  'loss {:4.2f}'.format(\n",
    "                      epoch, batch_idx, len(range(0, train_data.shape[0], args.batch_size)),\n",
    "                      elapsed * 1000 / args.log_interval,\n",
    "                      train_loss / args.log_interval))\n",
    "            start_time = time.time()\n",
    "\n",
    "    # Return average training loss\n",
    "    return train_loss / len(range(0, train_data.shape[0], args.batch_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miVnH38nI1QX"
   },
   "source": [
    "Evaluate 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "DkAgBBOfI1QX"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data, validation_data, loss_function, device, top_k=[10], anneal_cap=0.2, total_anneal_steps=20000):\n",
    "    \"\"\"\n",
    "    Evaluate the Multi-VAE model on validation data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Multi-VAE model instance\n",
    "    - train_data: csr_matrix, user-item interactions in the training set\n",
    "    - validation_data: csr_matrix, user-item interactions in the validation set\n",
    "    - loss_function: Loss function for VAE (e.g., loss_function_vae)\n",
    "    - device: PyTorch device (e.g., 'cuda' or 'cpu')\n",
    "    - top_k: List of k values for Recall@k and NDCG@k\n",
    "    - anneal_cap: Maximum annealing factor for KL divergence\n",
    "    - total_anneal_steps: Total steps for annealing KL divergence weight\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss: Average evaluation loss\n",
    "    - metrics: Dictionary containing Recall@k and NDCG@k for each k\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    update_count = 0\n",
    "    anneal = 0.0\n",
    "    recall_results = {k: [] for k in top_k}\n",
    "    ndcg_results = {k: [] for k in top_k}\n",
    "\n",
    "    num_users = validation_data.shape[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user in range(num_users):  # User-wise evaluation\n",
    "            # Get training and validation data for the current user\n",
    "            train_row = train_data[user].toarray()\n",
    "            val_row = validation_data[user].toarray()\n",
    "\n",
    "            # Convert to PyTorch tensors\n",
    "            train_tensor = torch.FloatTensor(train_row).to(device)\n",
    "            val_tensor = torch.FloatTensor(val_row).to(device)\n",
    "\n",
    "            # Annealing factor for KL divergence\n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1.0 * update_count / total_anneal_steps)\n",
    "\n",
    "            # Forward pass\n",
    "            recon_batch, mu, logvar = model(train_tensor)\n",
    "\n",
    "            # Compute loss (using validation data)\n",
    "            loss = loss_function(recon_batch, val_tensor, mu, logvar, anneal)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Exclude training interactions from recommendations\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            recon_batch[train_row.nonzero()] = -np.inf  # Mask training items\n",
    "\n",
    "            # Compute metrics for top_k\n",
    "            for k in top_k:\n",
    "                recall_results[k].append(Recall_at_k_batch(recon_batch, val_row, k))\n",
    "                ndcg_results[k].append(NDCG_binary_at_k_batch(recon_batch, val_row, k))\n",
    "\n",
    "            update_count += 1\n",
    "\n",
    "    # Compute average loss and metrics\n",
    "    avg_loss = total_loss / num_users\n",
    "    metrics = {\n",
    "        f\"Recall@{k}\": np.mean(recall_results[k]) for k in top_k\n",
    "    }\n",
    "    metrics.update({\n",
    "        f\"NDCG@{k}\": np.mean(ndcg_results[k]) for k in top_k\n",
    "    })\n",
    "\n",
    "    print(f\"Evaluation Loss: {avg_loss:.4f}\")\n",
    "    for k in top_k:\n",
    "        print(f\"Recall@{k}: {metrics[f'Recall@{k}']:.4f}, NDCG@{k}: {metrics[f'NDCG@{k}']:.4f}\")\n",
    "\n",
    "    return avg_loss, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB6ituFDVXOA"
   },
   "source": [
    "Metric 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "8EiyP7uMVY_t"
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    \"\"\"\n",
    "    Compute Recall@k for binary relevance.\n",
    "\n",
    "    Parameters:\n",
    "    - X_pred: numpy.ndarray, predicted scores for all items\n",
    "    - heldout_batch: numpy.ndarray or csr_matrix, true interactions for each user\n",
    "    - k: int, cutoff for Recall@k\n",
    "\n",
    "    Returns:\n",
    "    - recall: numpy.ndarray, Recall@k for each user in the batch\n",
    "    \"\"\"\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    # Convert heldout_batch to dense array if it's a sparse matrix\n",
    "    if isinstance(heldout_batch, np.ndarray):\n",
    "        X_true_binary = heldout_batch > 0\n",
    "    else:\n",
    "        X_true_binary = (heldout_batch > 0).toarray()\n",
    "\n",
    "    # Compute Recall@k\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall\n",
    "\n",
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    \"\"\"\n",
    "    Compute Normalized Discounted Cumulative Gain@k for binary relevance.\n",
    "\n",
    "    Parameters:\n",
    "    - X_pred: numpy.ndarray, predicted scores for all items\n",
    "    - heldout_batch: numpy.ndarray or csr_matrix, true interactions for each user\n",
    "    - k: int, cutoff for NDCG@k\n",
    "\n",
    "    Returns:\n",
    "    - ndcg: numpy.ndarray, NDCG@k for each user in the batch\n",
    "    \"\"\"\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "\n",
    "    # Convert heldout_batch to dense array if it's a sparse matrix\n",
    "    if isinstance(heldout_batch, np.ndarray):\n",
    "        X_true_binary = heldout_batch > 0\n",
    "    else:\n",
    "        X_true_binary = (heldout_batch > 0).toarray()\n",
    "\n",
    "    # Compute DCG\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "    DCG = (X_true_binary[np.arange(batch_users)[:, np.newaxis], idx_topk] * tp).sum(axis=1)\n",
    "\n",
    "    # Compute IDCG\n",
    "    IDCG = np.array([tp[:min(n, k)].sum() for n in X_true_binary.sum(axis=1)])\n",
    "    ndcg = DCG / IDCG\n",
    "    ndcg[np.isnan(ndcg)] = 0.0  # Handle NaN for users with no interactions\n",
    "    return ndcg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHteJm7kI1QX"
   },
   "source": [
    "학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "jxXhcO0GR-fZ"
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "anneal_cap = 0.2\n",
    "total_anneal_steps = 20000\n",
    "epochs = 10\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = train_data.shape[1]\n",
    "p_dims = [200,600,input_dim]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultiVAE(p_dims).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "update_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_IJ1bbAI1QY",
    "outputId": "c29b3c5b-8da7-47c4-c976-13b068543474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Training Loss: 1270.9060\n",
      "Evaluation Loss: 57.6237\n",
      "Recall@10: 0.0724, NDCG@10: 0.0545\n",
      "Validation Loss: 57.6237\n",
      "Recall@10: 0.0724, NDCG@10: 0.0545\n",
      "Epoch 2/20\n",
      "Training Loss: 1199.4623\n",
      "Evaluation Loss: 89.8114\n",
      "Recall@10: 0.0870, NDCG@10: 0.0650\n",
      "Validation Loss: 89.8114\n",
      "Recall@10: 0.0870, NDCG@10: 0.0650\n",
      "Epoch 3/20\n",
      "Training Loss: 1176.4330\n",
      "Evaluation Loss: 100.2679\n",
      "Recall@10: 0.0924, NDCG@10: 0.0709\n",
      "Validation Loss: 100.2679\n",
      "Recall@10: 0.0924, NDCG@10: 0.0709\n",
      "Epoch 4/20\n",
      "Training Loss: 1163.9082\n",
      "Evaluation Loss: 104.3858\n",
      "Recall@10: 0.1019, NDCG@10: 0.0782\n",
      "Validation Loss: 104.3858\n",
      "Recall@10: 0.1019, NDCG@10: 0.0782\n",
      "Epoch 5/20\n",
      "Training Loss: 1152.4798\n",
      "Evaluation Loss: 107.7782\n",
      "Recall@10: 0.1081, NDCG@10: 0.0822\n",
      "Validation Loss: 107.7782\n",
      "Recall@10: 0.1081, NDCG@10: 0.0822\n",
      "Epoch 6/20\n",
      "Training Loss: 1145.5294\n",
      "Evaluation Loss: 109.0502\n",
      "Recall@10: 0.1099, NDCG@10: 0.0833\n",
      "Validation Loss: 109.0502\n",
      "Recall@10: 0.1099, NDCG@10: 0.0833\n",
      "Epoch 7/20\n",
      "Training Loss: 1141.6498\n",
      "Evaluation Loss: 105.4764\n",
      "Recall@10: 0.1126, NDCG@10: 0.0862\n",
      "Validation Loss: 105.4764\n",
      "Recall@10: 0.1126, NDCG@10: 0.0862\n",
      "Epoch 8/20\n",
      "Training Loss: 1137.6458\n",
      "Evaluation Loss: 104.9126\n",
      "Recall@10: 0.1149, NDCG@10: 0.0873\n",
      "Validation Loss: 104.9126\n",
      "Recall@10: 0.1149, NDCG@10: 0.0873\n",
      "Epoch 9/20\n",
      "Training Loss: 1134.0191\n",
      "Evaluation Loss: 103.1512\n",
      "Recall@10: 0.1188, NDCG@10: 0.0908\n",
      "Validation Loss: 103.1512\n",
      "Recall@10: 0.1188, NDCG@10: 0.0908\n",
      "Epoch 10/20\n",
      "Training Loss: 1130.3298\n",
      "Evaluation Loss: 102.3333\n",
      "Recall@10: 0.1210, NDCG@10: 0.0926\n",
      "Validation Loss: 102.3333\n",
      "Recall@10: 0.1210, NDCG@10: 0.0926\n",
      "Epoch 11/20\n",
      "Training Loss: 1127.4253\n",
      "Evaluation Loss: 100.6841\n",
      "Recall@10: 0.1221, NDCG@10: 0.0935\n",
      "Validation Loss: 100.6841\n",
      "Recall@10: 0.1221, NDCG@10: 0.0935\n",
      "Epoch 12/20\n",
      "Training Loss: 1124.9865\n",
      "Evaluation Loss: 99.5899\n",
      "Recall@10: 0.1239, NDCG@10: 0.0944\n",
      "Validation Loss: 99.5899\n",
      "Recall@10: 0.1239, NDCG@10: 0.0944\n",
      "Epoch 13/20\n",
      "Training Loss: 1122.7803\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{args.epochs}\")\n",
    "    train_loss = train(model, loss_function_vae, optimizer, train_data, device, args, is_VAE=True)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    val_loss, metrics = evaluate(model, train_data, val_data, loss_function_vae, device, top_k=[10])\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    for k in [10]:\n",
    "        print(f\"Recall@{k}: {metrics[f'Recall@{k}']:.4f}, NDCG@{k}: {metrics[f'NDCG@{k}']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission 용 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train/valid set으로 나누지 않은 전체 데이터를 포함하고 있는 interaction matrix를 학습시킵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = interaction_matrix.shape[0]\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "anneal_cap = 0.2\n",
    "total_anneal_steps = 20000\n",
    "epochs = 10\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = train_data.shape[1]\n",
    "p_dims = [200,600,input_dim]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultiVAE(p_dims).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "update_count = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{args.epochs}\")\n",
    "    train_loss = train(model, loss_function_vae, optimizer, interaction_matrix, device, args, is_VAE=True)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터셋으로 학습된 모델을 이용해 interaction이 진행된 아이템을 제외하고 나머지를 model을 사용해 10개의 아이템을 추천합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(model, interaction_matrix, user_mapping, item_mapping, top_k=10):\n",
    "    \"\"\"\n",
    "    Generate top-k recommendations for each user after masking existing interactions.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained VAE model\n",
    "    - interaction_matrix: Original interaction matrix (csr_matrix)\n",
    "    - user_mapping: Mapping from original to reindexed user IDs\n",
    "    - item_mapping: Mapping from original to reindexed item IDs\n",
    "    - top_k: Number of recommendations to generate per user\n",
    "\n",
    "    Returns:\n",
    "    - recommendations: pd.DataFrame, user-to-top-k recommended items\n",
    "    \"\"\"\n",
    "    # Reconstruct the interaction matrix using the trained model\n",
    "    interaction_tensor = torch.FloatTensor(interaction_matrix.toarray()).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(interaction_tensor)[0].cpu().numpy()\n",
    "\n",
    "    # Mask already interacted items\n",
    "    masked_reconstructed = reconstructed * (interaction_matrix.toarray() == 0)\n",
    "\n",
    "    # Get top-k recommendations for each user\n",
    "    recommendations = []\n",
    "    for user_id, scores in enumerate(masked_reconstructed):\n",
    "        top_items = np.argsort(scores)[-top_k:][::-1]  # Get top-k items sorted by score\n",
    "        for item_id in top_items:\n",
    "            recommendations.append([user_id, item_id])\n",
    "\n",
    "    # Map back to original user and item IDs\n",
    "    reverse_user_mapping = {v: k for k, v in user_mapping.items()}\n",
    "    reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
    "    recommendations_df = pd.DataFrame(recommendations, columns=[\"user\", \"item\"])\n",
    "    recommendations_df[\"user\"] = recommendations_df[\"user\"].map(reverse_user_mapping)\n",
    "    recommendations_df[\"item\"] = recommendations_df[\"item\"].map(reverse_item_mapping)\n",
    "\n",
    "    return recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = generate_recommendations(model, interaction_matrix, usr2idx_dict, item2idx_dict, top_k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
