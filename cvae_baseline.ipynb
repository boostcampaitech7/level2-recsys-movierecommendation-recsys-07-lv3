{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import bottleneck as bn\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument parser 설정\n",
    "parser = argparse.ArgumentParser(description='PyTorch Conditional Variational Autoencoders for Collaborative Filtering')\n",
    "parser.add_argument('--lr', type=float, default=1e-5,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--wd', type=float, default=1e-5,\n",
    "                    help='weight decay coefficient')\n",
    "parser.add_argument('--batch_size', type=int, default=500,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='upper epoch limit')\n",
    "parser.add_argument('--total_anneal_steps', type=int, default=100000,\n",
    "                    help='the total number of gradient updates for annealing')\n",
    "parser.add_argument('--anneal_cap', type=float, default=0.5,\n",
    "                    help='largest annealing parameter')\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='use CUDA')\n",
    "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n",
    "                    help='report interval')\n",
    "parser.add_argument('--save', type=str, default='model.pt',\n",
    "                    help='path to save the final model')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/data/ephemeral/home/data/train/train_ratings.csv')\n",
    "\n",
    "titles = pd.read_csv('/data/ephemeral/home/data/train/titles.tsv', sep='\\t')\n",
    "years = pd.read_csv('/data/ephemeral/home/data/train/years.tsv', sep='\\t')\n",
    "directors = pd.read_csv('/data/ephemeral/home/data/train/directors.tsv', sep='\\t')\n",
    "genres = pd.read_csv('/data/ephemeral/home/data/train/genres.tsv', sep='\\t')\n",
    "writers = pd.read_csv('/data/ephemeral/home/data/train/writers.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제목에서 연도 추출 함수 정의\n",
    "def extract_year(title):\n",
    "    match = re.search(r'\\((\\d{4})\\)', title)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return np.nan  # 연도를 찾지 못한 경우 NaN 반환\n",
    "\n",
    "# 제목 데이터에서 연도 추출\n",
    "titles['year_extracted'] = titles['title'].apply(extract_year)\n",
    "\n",
    "# 기존 연도 데이터와 추출한 연도 데이터를 병합\n",
    "years = years.merge(titles[['item', 'year_extracted']], on='item', how='left')\n",
    "years['year'] = years['year'].fillna(years['year_extracted'])\n",
    "years = years.drop(columns=['year_extracted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_column(data, column_name):\n",
    "    \"\"\"\n",
    "    Reindex a column in the dataframe to ensure continuous indices starting from 0.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pd.DataFrame, the input dataframe.\n",
    "    - column_name: str, the column to reindex.\n",
    "\n",
    "    Returns:\n",
    "    - data: pd.DataFrame, the dataframe with reindexed column.\n",
    "    - mapping_dict: dict, the original-to-new mapping dictionary.\n",
    "    \"\"\"\n",
    "    # Create the mapping dictionary\n",
    "    mapping_dict = {original_id: new_id for new_id, original_id in enumerate(data[column_name].unique())}\n",
    "\n",
    "    # Apply the mapping to the dataframe\n",
    "    data[column_name] = data[column_name].map(mapping_dict)\n",
    "\n",
    "    return data, mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df에 인덱스 매핑 적용\n",
    "original_df = train_df.copy()\n",
    "train_df, usr2idx_dict = reindex_column(train_df, 'user')\n",
    "train_df, item2idx_dict = reindex_column(train_df, 'item')\n",
    "\n",
    "# 다른 데이터프레임에 아이템 인덱스 매핑 적용\n",
    "genres['item'] = genres['item'].map(item2idx_dict)\n",
    "titles['item'] = titles['item'].map(item2idx_dict)\n",
    "years['item'] = years['item'].map(item2idx_dict)\n",
    "directors['item'] = directors['item'].map(item2idx_dict)\n",
    "writers['item'] = writers['item'].map(item2idx_dict)\n",
    "\n",
    "# 학습 데이터에 없는 아이템 제거 및 타입 변환\n",
    "dataframes = [genres, titles, years, directors, writers]\n",
    "for df in dataframes:\n",
    "    df.dropna(subset=['item'], inplace=True)\n",
    "    df['item'] = df['item'].astype(int)\n",
    "\n",
    "# **3. 상호작용 행렬 생성**\n",
    "\n",
    "# csr_matrix 생성에 필요한 요소 추출\n",
    "row = train_df['user'].values\n",
    "col = train_df['item'].values\n",
    "data = np.ones_like(row)\n",
    "\n",
    "# 사용자 수와 아이템 수\n",
    "num_users = train_df['user'].nunique()\n",
    "num_items = train_df['item'].nunique()\n",
    "\n",
    "# 상호작용 행렬 생성\n",
    "interaction_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Split the interaction matrix into training and validation sets.\n",
    "    The validation set will include both sequential and static items in a 1:1 ratio.\n",
    "    \n",
    "    Parameters:\n",
    "    - interaction_matrix: csr_matrix, the full user-item interaction matrix.\n",
    "    \n",
    "    Returns:\n",
    "    - train_matrix: csr_matrix, training set interactions.\n",
    "    - validation_matrix: csr_matrix, validation set interactions.\n",
    "    \"\"\"\n",
    "    train_rows, train_cols, train_data = [], [], []\n",
    "    val_rows, val_cols, val_data = [], [], []\n",
    "    \n",
    "    for user in range(interaction_matrix.shape[0]):\n",
    "        item_indices = interaction_matrix[user].nonzero()[1]\n",
    "        timestamps = interaction_matrix[user].data  # 각 상호작용의 타임스탬프\n",
    "        \n",
    "        if len(item_indices) == 0:\n",
    "            continue  # 상호작용이 없는 사용자 건너뜀\n",
    "        \n",
    "        # 아이템과 타임스탬프를 함께 정렬 (타임스탬프 기준)\n",
    "        sorted_items = [x for _, x in sorted(zip(timestamps, item_indices))]\n",
    "        \n",
    "        num_items = len(sorted_items)\n",
    "        num_val_items = max(2, int(0.2 * num_items))  # 최소 2개의 검증 아이템 (순차적, 정적)\n",
    "        \n",
    "        # Sequential 아이템: 마지막 아이템\n",
    "        sequential_item = sorted_items[-1]\n",
    "        \n",
    "        # Static 아이템: 나머지 아이템 중에서 무작위로 선택\n",
    "        remaining_items = sorted_items[:-1]\n",
    "        if len(remaining_items) > 0:\n",
    "            num_static_items = num_val_items // 2\n",
    "            static_items = np.random.choice(remaining_items, size=num_static_items, replace=False).tolist()\n",
    "        else:\n",
    "            static_items = []\n",
    "        \n",
    "        # 검증 세트 아이템 (순차적 + 정적)\n",
    "        val_items = [sequential_item] + static_items\n",
    "        \n",
    "        # 학습 세트 아이템\n",
    "        train_items = list(set(sorted_items) - set(val_items))\n",
    "        \n",
    "        # 학습 세트 데이터 추가\n",
    "        train_rows.extend([user] * len(train_items))\n",
    "        train_cols.extend(train_items)\n",
    "        train_data.extend([1] * len(train_items))\n",
    "        \n",
    "        # 검증 세트 데이터 추가\n",
    "        val_rows.extend([user] * len(val_items))\n",
    "        val_cols.extend(val_items)\n",
    "        val_data.extend([1] * len(val_items))\n",
    "    \n",
    "    # CSR 행렬 생성\n",
    "    train_matrix = csr_matrix((train_data, (train_rows, train_cols)), shape=interaction_matrix.shape)\n",
    "    validation_matrix = csr_matrix((val_data, (val_rows, val_cols)), shape=interaction_matrix.shape)\n",
    "    \n",
    "    return train_matrix, validation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_validation_split(interaction_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 아이템 ID 리스트 생성\n",
    "all_items = pd.DataFrame({'item': np.arange(num_items)})\n",
    "\n",
    "# 장르 처리\n",
    "item_genres = genres.groupby('item')['genre'].apply(list).reset_index()\n",
    "item_genres = all_items.merge(item_genres, on='item', how='left')\n",
    "item_genres['genre'] = item_genres['genre'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "mlb_genres = MultiLabelBinarizer()\n",
    "genre_matrix = mlb_genres.fit_transform(item_genres['genre'])\n",
    "\n",
    "# 감독 처리\n",
    "item_directors = directors.groupby('item')['director'].apply(list).reset_index()\n",
    "item_directors = all_items.merge(item_directors, on='item', how='left')\n",
    "item_directors['director'] = item_directors['director'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "mlb_directors = MultiLabelBinarizer()\n",
    "director_matrix = mlb_directors.fit_transform(item_directors['director'])\n",
    "\n",
    "# 작가 처리\n",
    "item_writers = writers.groupby('item')['writer'].apply(list).reset_index()\n",
    "item_writers = all_items.merge(item_writers, on='item', how='left')\n",
    "item_writers['writer'] = item_writers['writer'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "mlb_writers = MultiLabelBinarizer()\n",
    "writer_matrix = mlb_writers.fit_transform(item_writers['writer'])\n",
    "\n",
    "# 연도 처리\n",
    "item_years = years[['item', 'year']]\n",
    "item_years = all_items.merge(item_years, on='item', how='left')\n",
    "# 결측값을 중간값으로 대체\n",
    "median_year = item_years['year'].median()\n",
    "item_years['year'] = item_years['year'].fillna(median_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "scaler_year = StandardScaler()\n",
    "item_years['year_scaled'] = scaler_year.fit_transform(item_years[['year']])\n",
    "year_matrix = item_years[['year_scaled']].values\n",
    "\n",
    "# **6. 특징 행렬 결합**\n",
    "\n",
    "# 특징 행렬 연결\n",
    "item_feature_matrix = np.hstack([\n",
    "    genre_matrix,\n",
    "    director_matrix,\n",
    "    writer_matrix,\n",
    "    year_matrix\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **7. 조건부 변수 딕셔너리 생성**\n",
    "\n",
    "# 아이템별 조건부 변수 딕셔너리 생성\n",
    "item_conditional = {item: torch.FloatTensor(features) for item, features in zip(all_items['item'], item_feature_matrix)}\n",
    "\n",
    "# 조건부 변수의 차원 및 기본값 설정\n",
    "cond_dim = item_feature_matrix.shape[1]\n",
    "default_cond = torch.zeros(cond_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE 모델 정의\n",
    "class MultiCVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-CVAE.\n",
    "\n",
    "    Multi-CVAE : Conditional Variational Autoencoder with Multinomial Likelihood\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, p_dims, q_dims=None, cond_dim=0, dropout=0.5):\n",
    "        super(MultiCVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        self.cond_dim = cond_dim  # 조건부 변수의 차원\n",
    "\n",
    "        if q_dims:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimensions must equal to each other\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        else:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "\n",
    "        # 인코더 레이어 설정\n",
    "        temp_q_dims = [self.q_dims[0] + cond_dim] + self.q_dims[1:-1] + [self.q_dims[-1] * 2]\n",
    "        self.q_layers = nn.ModuleList()\n",
    "        for d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:]):\n",
    "            self.q_layers.append(nn.Linear(d_in, d_out))\n",
    "\n",
    "        # 디코더 레이어 설정\n",
    "        temp_p_dims = [self.p_dims[0]] + self.p_dims[1:]\n",
    "        self.p_layers = nn.ModuleList()\n",
    "        for i, (d_in, d_out) in enumerate(zip(temp_p_dims[:-1], temp_p_dims[1:])):\n",
    "            if i > 0:\n",
    "                d_in += cond_dim  # 조건부 변수의 차원을 입력 차원에 더해줌\n",
    "            self.p_layers.append(nn.Linear(d_in, d_out))\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input, cond):\n",
    "        mu, logvar = self.encode(input, cond)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, cond), mu, logvar\n",
    "\n",
    "    def encode(self, input, cond):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "        h = torch.cat([h, cond], dim=1)  # 조건부 변수와 결합\n",
    "\n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                mu = h[:, :self.q_dims[-1]]\n",
    "                logvar = h[:, self.q_dims[-1]:]\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z, cond):\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            if i > 0:\n",
    "                h = torch.cat([h, cond], dim=1)  # 조건부 변수와 결합\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.q_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0 / (fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "\n",
    "        for layer in self.p_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0 / (fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n",
    "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "\n",
    "    return BCE + anneal * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sparse2tensor(data):\n",
    "    return torch.FloatTensor(data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conditional_variable(data_batch):\n",
    "    \"\"\"\n",
    "    각 사용자에 대한 조건부 변수를 생성합니다.\n",
    "    사용자별로 본 아이템들의 조건부 변수 평균을 계산합니다.\n",
    "    \"\"\"\n",
    "    cond_list = []\n",
    "    for user_interactions in data_batch:\n",
    "        # user_interactions는 scipy.sparse의 행 벡터입니다.\n",
    "        item_indices = user_interactions.nonzero()[1]  # 열 인덱스를 가져옵니다.\n",
    "        item_indices = item_indices.tolist()\n",
    "        item_conds = [item_conditional.get(item, default_cond) for item in item_indices]\n",
    "        if item_conds:\n",
    "            cond = torch.stack(item_conds).mean(dim=0)\n",
    "        else:\n",
    "            cond = default_cond\n",
    "        cond_list.append(cond)\n",
    "    cond_tensor = torch.stack(cond_list)\n",
    "    return cond_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_data, device, args):\n",
    "    \"\"\"\n",
    "    Train the model on the given training data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: PyTorch model\n",
    "    - criterion: Loss function\n",
    "    - optimizer: Optimizer for training\n",
    "    - train_data: csr_matrix, training data\n",
    "    - device: PyTorch device (e.g., 'cuda' or 'cpu')\n",
    "    - args: Arguments containing hyperparameters\n",
    "\n",
    "    Returns:\n",
    "    - train_loss: Average training loss over all batches\n",
    "    \"\"\"\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    global update_count\n",
    "\n",
    "    for batch_idx, start_idx in enumerate(range(0, train_data.shape[0], args.batch_size)):\n",
    "        end_idx = min(start_idx + args.batch_size, train_data.shape[0])\n",
    "        data = train_data[start_idx:end_idx]\n",
    "        data_tensor = naive_sparse2tensor(data).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 조건부 변수 생성\n",
    "        cond = get_conditional_variable(data)\n",
    "        cond = cond.to(device)\n",
    "\n",
    "        if args.total_anneal_steps > 0:\n",
    "            anneal = min(args.anneal_cap, 1. * update_count / args.total_anneal_steps)\n",
    "        else:\n",
    "            anneal = args.anneal_cap\n",
    "\n",
    "        # Forward pass and loss computation\n",
    "        recon_batch, mu, logvar = model(data_tensor, cond)\n",
    "        loss = loss_function_vae(recon_batch, data_tensor, mu, logvar, anneal)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        update_count += 1\n",
    "\n",
    "        # Log progress\n",
    "        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
    "                  'loss {:4.2f}'.format(\n",
    "                      epoch, batch_idx, len(range(0, train_data.shape[0], args.batch_size)),\n",
    "                      elapsed * 1000 / args.log_interval,\n",
    "                      train_loss / args.log_interval))\n",
    "            start_time = time.time()\n",
    "            train_loss = 0.0\n",
    "\n",
    "    # Return average training loss\n",
    "    return train_loss / len(range(0, train_data.shape[0], args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, train_data, validation_data, loss_function, device, top_k=[10], anneal_cap=0.2, total_anneal_steps=20000):\n",
    "    \"\"\"\n",
    "    Evaluate the Multi-CVAE model on validation data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Multi-CVAE model instance\n",
    "    - train_data: csr_matrix, user-item interactions in the training set\n",
    "    - validation_data: csr_matrix, user-item interactions in the validation set\n",
    "    - loss_function: Loss function for VAE (e.g., loss_function_vae)\n",
    "    - device: PyTorch device (e.g., 'cuda' or 'cpu')\n",
    "    - top_k: List of k values for Recall@k and NDCG@k\n",
    "    - anneal_cap: Maximum annealing factor for KL divergence\n",
    "    - total_anneal_steps: Total steps for annealing KL divergence weight\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss: Average evaluation loss\n",
    "    - metrics: Dictionary containing Recall@k and NDCG@k for each k\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    update_count = 0\n",
    "    anneal = 0.0\n",
    "    recall_results = {k: [] for k in top_k}\n",
    "    ndcg_results = {k: [] for k in top_k}\n",
    "\n",
    "    num_users = validation_data.shape[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(0, num_users, args.batch_size):\n",
    "            end_idx = min(start_idx + args.batch_size, num_users)\n",
    "            data_batch = train_data[start_idx:end_idx]\n",
    "            data_tensor = naive_sparse2tensor(data_batch).to(device)\n",
    "            val_batch = validation_data[start_idx:end_idx]\n",
    "            val_tensor = naive_sparse2tensor(val_batch).to(device)\n",
    "\n",
    "            # 조건부 변수 생성\n",
    "            cond = get_conditional_variable(data_batch)\n",
    "            cond = cond.to(device)\n",
    "\n",
    "            # Annealing factor for KL divergence\n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1.0 * update_count / total_anneal_steps)\n",
    "\n",
    "            # Forward pass\n",
    "            recon_batch, mu, logvar = model(data_tensor, cond)\n",
    "\n",
    "            # Compute loss (using validation data)\n",
    "            loss = loss_function(recon_batch, val_tensor, mu, logvar, anneal)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Exclude training interactions from recommendations\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            data_batch = data_batch.toarray()\n",
    "            recon_batch[data_batch.nonzero()] = -np.inf  # Mask training items\n",
    "\n",
    "            val_tensor = val_tensor.cpu().numpy()\n",
    "\n",
    "            # Compute metrics for top_k\n",
    "            for k in top_k:\n",
    "                recall = Recall_at_k_batch(recon_batch, val_tensor, k)\n",
    "                ndcg = NDCG_binary_at_k_batch(recon_batch, val_tensor, k)\n",
    "                recall_results[k].extend(recall)\n",
    "                ndcg_results[k].extend(ndcg)\n",
    "\n",
    "            update_count += 1\n",
    "\n",
    "    # Compute average loss and metrics\n",
    "    avg_loss = total_loss / num_users\n",
    "    metrics = {\n",
    "        f\"Recall@{k}\": np.mean(recall_results[k]) for k in top_k\n",
    "    }\n",
    "    metrics.update({\n",
    "        f\"NDCG@{k}\": np.mean(ndcg_results[k]) for k in top_k\n",
    "    })\n",
    "\n",
    "    print(f\"Evaluation Loss: {avg_loss:.4f}\")\n",
    "    for k in top_k:\n",
    "        print(f\"Recall@{k}: {metrics[f'Recall@{k}']:.4f}, NDCG@{k}: {metrics[f'NDCG@{k}']:.4f}\")\n",
    "\n",
    "    return avg_loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    \"\"\"\n",
    "    Compute Recall@k for binary relevance.\n",
    "\n",
    "    Parameters:\n",
    "    - X_pred: numpy.ndarray, predicted scores for all items\n",
    "    - heldout_batch: numpy.ndarray or csr_matrix, true interactions for each user\n",
    "    - k: int, cutoff for Recall@k\n",
    "\n",
    "    Returns:\n",
    "    - recall: numpy.ndarray, Recall@k for each user in the batch\n",
    "    \"\"\"\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    # Convert heldout_batch to dense array if it's a sparse matrix\n",
    "    if isinstance(heldout_batch, np.ndarray):\n",
    "        X_true_binary = heldout_batch > 0\n",
    "    else:\n",
    "        X_true_binary = (heldout_batch > 0).toarray()\n",
    "\n",
    "    # Compute Recall@k\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    \"\"\"\n",
    "    Compute Normalized Discounted Cumulative Gain@k for binary relevance.\n",
    "\n",
    "    Parameters:\n",
    "    - X_pred: numpy.ndarray, predicted scores for all items\n",
    "    - heldout_batch: numpy.ndarray or csr_matrix, true interactions for each user\n",
    "    - k: int, cutoff for NDCG@k\n",
    "\n",
    "    Returns:\n",
    "    - ndcg: numpy.ndarray, NDCG@k for each user in the batch\n",
    "    \"\"\"\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "\n",
    "    # Convert heldout_batch to dense array if it's a sparse matrix\n",
    "    if isinstance(heldout_batch, np.ndarray):\n",
    "        X_true_binary = heldout_batch > 0\n",
    "    else:\n",
    "        X_true_binary = (heldout_batch > 0).toarray()\n",
    "\n",
    "    # Compute DCG\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "    DCG = (X_true_binary[np.arange(batch_users)[:, np.newaxis], idx_topk] * tp).sum(axis=1)\n",
    "\n",
    "    # Compute IDCG\n",
    "    IDCG = np.array([tp[:min(n, k)].sum() for n in X_true_binary.sum(axis=1)])\n",
    "    ndcg = DCG / IDCG\n",
    "    ndcg[np.isnan(ndcg)] = 0.0  # Handle NaN for users with no interactions\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3  # 학습률 증가\n",
    "anneal_cap = 0.5\n",
    "total_anneal_steps = 10000\n",
    "epochs = args.epochs\n",
    "\n",
    "# args 객체에 하이퍼파라미터 업데이트\n",
    "args.lr = learning_rate\n",
    "args.anneal_cap = anneal_cap\n",
    "args.total_anneal_steps = total_anneal_steps\n",
    "args.batch_size = 500  # 필요한 경우 배치 크기 설정\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = train_data.shape[1]\n",
    "latent_dim = 800\n",
    "p_dims = [latent_dim, 800, input_dim]\n",
    "cond_dim = item_feature_matrix.shape[1]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultiCVAE(p_dims, cond_dim=cond_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# 학습률 스케줄러 설정 (중복 정의 제거)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # 5 에포크마다 학습률 50% 감소\n",
    "\n",
    "# Early Stopping 관련 변수 초기화\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "\n",
    "update_count = 0  # 업데이트 횟수 초기화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Training Loss: 1155.6392\n",
      "Evaluation Loss: 0.2658\n",
      "Recall@10: 0.1431, NDCG@10: 0.1577\n",
      "Validation Loss: 0.2658\n",
      "Recall@10: 0.1431, NDCG@10: 0.1577\n",
      "Best model saved.\n",
      "Epoch 2/100\n",
      "Training Loss: 1097.0309\n",
      "Evaluation Loss: 0.2588\n",
      "Recall@10: 0.1695, NDCG@10: 0.1844\n",
      "Validation Loss: 0.2588\n",
      "Recall@10: 0.1695, NDCG@10: 0.1844\n",
      "Best model saved.\n",
      "Epoch 3/100\n",
      "Training Loss: 1074.0266\n",
      "Evaluation Loss: 0.2546\n",
      "Recall@10: 0.1906, NDCG@10: 0.2062\n",
      "Validation Loss: 0.2546\n",
      "Recall@10: 0.1906, NDCG@10: 0.2062\n",
      "Best model saved.\n",
      "Epoch 4/100\n",
      "Training Loss: 1059.8747\n",
      "Evaluation Loss: 0.2524\n",
      "Recall@10: 0.1959, NDCG@10: 0.2094\n",
      "Validation Loss: 0.2524\n",
      "Recall@10: 0.1959, NDCG@10: 0.2094\n",
      "Best model saved.\n",
      "Epoch 5/100\n",
      "Training Loss: 1051.1633\n",
      "Evaluation Loss: 0.2511\n",
      "Recall@10: 0.2018, NDCG@10: 0.2147\n",
      "Validation Loss: 0.2511\n",
      "Recall@10: 0.2018, NDCG@10: 0.2147\n",
      "Best model saved.\n",
      "Epoch 6/100\n",
      "Training Loss: 1045.7224\n",
      "Evaluation Loss: 0.2502\n",
      "Recall@10: 0.2120, NDCG@10: 0.2284\n",
      "Validation Loss: 0.2502\n",
      "Recall@10: 0.2120, NDCG@10: 0.2284\n",
      "Best model saved.\n",
      "Epoch 7/100\n",
      "Training Loss: 1043.7116\n",
      "Evaluation Loss: 0.2499\n",
      "Recall@10: 0.2158, NDCG@10: 0.2329\n",
      "Validation Loss: 0.2499\n",
      "Recall@10: 0.2158, NDCG@10: 0.2329\n",
      "Best model saved.\n",
      "Epoch 8/100\n",
      "Training Loss: 1041.9319\n",
      "Evaluation Loss: 0.2495\n",
      "Recall@10: 0.2163, NDCG@10: 0.2324\n",
      "Validation Loss: 0.2495\n",
      "Recall@10: 0.2163, NDCG@10: 0.2324\n",
      "Best model saved.\n",
      "Epoch 9/100\n",
      "Training Loss: 1040.3106\n",
      "Evaluation Loss: 0.2492\n",
      "Recall@10: 0.2185, NDCG@10: 0.2352\n",
      "Validation Loss: 0.2492\n",
      "Recall@10: 0.2185, NDCG@10: 0.2352\n",
      "Best model saved.\n",
      "Epoch 10/100\n",
      "Training Loss: 1038.9367\n",
      "Evaluation Loss: 0.2489\n",
      "Recall@10: 0.2210, NDCG@10: 0.2370\n",
      "Validation Loss: 0.2489\n",
      "Recall@10: 0.2210, NDCG@10: 0.2370\n",
      "Best model saved.\n",
      "Epoch 11/100\n",
      "Training Loss: 1036.9342\n",
      "Evaluation Loss: 0.2486\n",
      "Recall@10: 0.2261, NDCG@10: 0.2440\n",
      "Validation Loss: 0.2486\n",
      "Recall@10: 0.2261, NDCG@10: 0.2440\n",
      "Best model saved.\n",
      "Epoch 12/100\n",
      "Training Loss: 1036.2767\n",
      "Evaluation Loss: 0.2484\n",
      "Recall@10: 0.2276, NDCG@10: 0.2460\n",
      "Validation Loss: 0.2484\n",
      "Recall@10: 0.2276, NDCG@10: 0.2460\n",
      "Best model saved.\n",
      "Epoch 13/100\n",
      "Training Loss: 1035.8157\n",
      "Evaluation Loss: 0.2483\n",
      "Recall@10: 0.2286, NDCG@10: 0.2466\n",
      "Validation Loss: 0.2483\n",
      "Recall@10: 0.2286, NDCG@10: 0.2466\n",
      "Best model saved.\n",
      "Epoch 14/100\n",
      "Training Loss: 1035.3499\n",
      "Evaluation Loss: 0.2482\n",
      "Recall@10: 0.2296, NDCG@10: 0.2475\n",
      "Validation Loss: 0.2482\n",
      "Recall@10: 0.2296, NDCG@10: 0.2475\n",
      "Best model saved.\n",
      "Epoch 15/100\n",
      "Training Loss: 1034.9856\n",
      "Evaluation Loss: 0.2482\n",
      "Recall@10: 0.2315, NDCG@10: 0.2499\n",
      "Validation Loss: 0.2482\n",
      "Recall@10: 0.2315, NDCG@10: 0.2499\n",
      "Best model saved.\n",
      "Epoch 16/100\n",
      "Training Loss: 1034.2963\n",
      "Evaluation Loss: 0.2479\n",
      "Recall@10: 0.2328, NDCG@10: 0.2514\n",
      "Validation Loss: 0.2479\n",
      "Recall@10: 0.2328, NDCG@10: 0.2514\n",
      "Best model saved.\n",
      "Epoch 17/100\n",
      "Training Loss: 1034.2921\n",
      "Evaluation Loss: 0.2478\n",
      "Recall@10: 0.2330, NDCG@10: 0.2514\n",
      "Validation Loss: 0.2478\n",
      "Recall@10: 0.2330, NDCG@10: 0.2514\n",
      "Best model saved.\n",
      "Epoch 18/100\n",
      "Training Loss: 1034.2436\n",
      "Evaluation Loss: 0.2478\n",
      "Recall@10: 0.2336, NDCG@10: 0.2518\n",
      "Validation Loss: 0.2478\n",
      "Recall@10: 0.2336, NDCG@10: 0.2518\n",
      "Best model saved.\n",
      "Epoch 19/100\n",
      "Training Loss: 1034.3054\n",
      "Evaluation Loss: 0.2477\n",
      "Recall@10: 0.2344, NDCG@10: 0.2532\n",
      "Validation Loss: 0.2477\n",
      "Recall@10: 0.2344, NDCG@10: 0.2532\n",
      "Best model saved.\n",
      "Epoch 20/100\n",
      "Training Loss: 1034.3588\n",
      "Evaluation Loss: 0.2477\n",
      "Recall@10: 0.2350, NDCG@10: 0.2542\n",
      "Validation Loss: 0.2477\n",
      "Recall@10: 0.2350, NDCG@10: 0.2542\n",
      "Best model saved.\n",
      "Epoch 21/100\n",
      "Training Loss: 1034.2059\n",
      "Evaluation Loss: 0.2477\n",
      "Recall@10: 0.2353, NDCG@10: 0.2541\n",
      "Validation Loss: 0.2477\n",
      "Recall@10: 0.2353, NDCG@10: 0.2541\n",
      "Best model saved.\n",
      "Epoch 22/100\n",
      "Training Loss: 1034.3995\n",
      "Evaluation Loss: 0.2476\n",
      "Recall@10: 0.2354, NDCG@10: 0.2538\n",
      "Validation Loss: 0.2476\n",
      "Recall@10: 0.2354, NDCG@10: 0.2538\n",
      "Best model saved.\n",
      "Epoch 23/100\n",
      "Training Loss: 1034.6330\n",
      "Evaluation Loss: 0.2477\n",
      "Recall@10: 0.2367, NDCG@10: 0.2558\n",
      "Validation Loss: 0.2477\n",
      "Recall@10: 0.2367, NDCG@10: 0.2558\n",
      "Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 24/100\n",
      "Training Loss: 1034.8530\n",
      "Evaluation Loss: 0.2476\n",
      "Recall@10: 0.2364, NDCG@10: 0.2551\n",
      "Validation Loss: 0.2476\n",
      "Recall@10: 0.2364, NDCG@10: 0.2551\n",
      "Best model saved.\n",
      "Epoch 25/100\n",
      "Training Loss: 1034.9714\n",
      "Evaluation Loss: 0.2476\n",
      "Recall@10: 0.2369, NDCG@10: 0.2556\n",
      "Validation Loss: 0.2476\n",
      "Recall@10: 0.2369, NDCG@10: 0.2556\n",
      "Best model saved.\n",
      "Epoch 26/100\n",
      "Training Loss: 1035.1282\n",
      "Evaluation Loss: 0.2475\n",
      "Recall@10: 0.2375, NDCG@10: 0.2565\n",
      "Validation Loss: 0.2475\n",
      "Recall@10: 0.2375, NDCG@10: 0.2565\n",
      "Best model saved.\n",
      "Epoch 27/100\n",
      "Training Loss: 1035.4644\n",
      "Evaluation Loss: 0.2475\n",
      "Recall@10: 0.2371, NDCG@10: 0.2558\n",
      "Validation Loss: 0.2475\n",
      "Recall@10: 0.2371, NDCG@10: 0.2558\n",
      "Best model saved.\n",
      "Epoch 28/100\n",
      "Training Loss: 1035.7330\n",
      "Evaluation Loss: 0.2475\n",
      "Recall@10: 0.2375, NDCG@10: 0.2565\n",
      "Validation Loss: 0.2475\n",
      "Recall@10: 0.2375, NDCG@10: 0.2565\n",
      "Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 29/100\n",
      "Training Loss: 1036.0374\n",
      "Evaluation Loss: 0.2475\n",
      "Recall@10: 0.2379, NDCG@10: 0.2569\n",
      "Validation Loss: 0.2475\n",
      "Recall@10: 0.2379, NDCG@10: 0.2569\n",
      "Validation loss did not improve for 2 epoch(s).\n",
      "Epoch 30/100\n",
      "Training Loss: 1036.3708\n",
      "Evaluation Loss: 0.2475\n",
      "Recall@10: 0.2375, NDCG@10: 0.2564\n",
      "Validation Loss: 0.2475\n",
      "Recall@10: 0.2375, NDCG@10: 0.2564\n",
      "Best model saved.\n",
      "Epoch 31/100\n",
      "Training Loss: 1036.5540\n",
      "Evaluation Loss: 0.2475\n",
      "Recall@10: 0.2379, NDCG@10: 0.2571\n",
      "Validation Loss: 0.2475\n",
      "Recall@10: 0.2379, NDCG@10: 0.2571\n",
      "Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 32/100\n",
      "Training Loss: 1036.8825\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2381, NDCG@10: 0.2572\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2381, NDCG@10: 0.2572\n",
      "Best model saved.\n",
      "Epoch 33/100\n",
      "Training Loss: 1037.2691\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2378, NDCG@10: 0.2570\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2378, NDCG@10: 0.2570\n",
      "Best model saved.\n",
      "Epoch 34/100\n",
      "Training Loss: 1037.5927\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2378, NDCG@10: 0.2569\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2378, NDCG@10: 0.2569\n",
      "Best model saved.\n",
      "Epoch 35/100\n",
      "Training Loss: 1037.8897\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2382, NDCG@10: 0.2575\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2382, NDCG@10: 0.2575\n",
      "Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 36/100\n",
      "Training Loss: 1038.1450\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2380, NDCG@10: 0.2573\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2380, NDCG@10: 0.2573\n",
      "Best model saved.\n",
      "Epoch 37/100\n",
      "Training Loss: 1038.4810\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2382, NDCG@10: 0.2575\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2382, NDCG@10: 0.2575\n",
      "Best model saved.\n",
      "Epoch 38/100\n",
      "Training Loss: 1038.8162\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2383, NDCG@10: 0.2576\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2383, NDCG@10: 0.2576\n",
      "Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 39/100\n",
      "Training Loss: 1039.1530\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2382, NDCG@10: 0.2575\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2382, NDCG@10: 0.2575\n",
      "Best model saved.\n",
      "Epoch 40/100\n",
      "Training Loss: 1039.4913\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2385, NDCG@10: 0.2579\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2385, NDCG@10: 0.2579\n",
      "Validation loss did not improve for 1 epoch(s).\n",
      "Epoch 41/100\n",
      "Training Loss: 1039.7156\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2383, NDCG@10: 0.2577\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2383, NDCG@10: 0.2577\n",
      "Validation loss did not improve for 2 epoch(s).\n",
      "Epoch 42/100\n",
      "Training Loss: 1040.0841\n",
      "Evaluation Loss: 0.2474\n",
      "Recall@10: 0.2385, NDCG@10: 0.2581\n",
      "Validation Loss: 0.2474\n",
      "Recall@10: 0.2385, NDCG@10: 0.2581\n",
      "Validation loss did not improve for 3 epoch(s).\n",
      "Early stopping at epoch 42\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    \n",
    "    # 훈련 단계\n",
    "    train_loss = train(model, loss_function_vae, optimizer, train_data, device, args)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # 검증 단계\n",
    "    val_loss, metrics = evaluate(model, train_data, val_data, loss_function_vae, device, top_k=[10])\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    for k in [10]:\n",
    "        print(f\"Recall@{k}: {metrics[f'Recall@{k}']:.4f}, NDCG@{k}: {metrics[f'NDCG@{k}']:.4f}\")\n",
    "    \n",
    "    # 학습률 스케줄러 업데이트\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        trigger_times = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(\"Best model saved.\")\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        print(f\"Validation loss did not improve for {trigger_times} epoch(s).\")\n",
    "        \n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 최적 모델 로드\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 2. 전체 사용자 데이터 준비\n",
    "num_users = train_df['user'].nunique()\n",
    "num_items = train_df['item'].nunique()\n",
    "\n",
    "row = train_df['user'].values\n",
    "col = train_df['item'].values\n",
    "data = np.ones_like(row)\n",
    "full_interaction_matrix = csr_matrix((data, (row, col)), shape=(num_users, num_items))\n",
    "\n",
    "# 3. 조건부 변수 생성\n",
    "def get_conditional_variable_all_users(data_matrix):\n",
    "    cond_list = []\n",
    "    num_users = data_matrix.shape[0]\n",
    "    for idx in range(num_users):\n",
    "        user_interactions = data_matrix.getrow(idx)\n",
    "        item_indices = user_interactions.nonzero()[1].tolist()\n",
    "        item_conds = [item_conditional.get(item, default_cond) for item in item_indices]\n",
    "        if item_conds:\n",
    "            cond = torch.stack(item_conds).mean(dim=0)\n",
    "        else:\n",
    "            cond = default_cond\n",
    "        cond_list.append(cond.numpy())\n",
    "    cond_tensor = torch.FloatTensor(np.array(cond_list))\n",
    "    return cond_tensor\n",
    "\n",
    "user_conditional = get_conditional_variable_all_users(full_interaction_matrix)\n",
    "user_conditional = user_conditional.to(device)\n",
    "\n",
    "# 4. 예측 생성\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    data_tensor = naive_sparse2tensor(full_interaction_matrix).to(device)\n",
    "    batch_size = args.batch_size\n",
    "    num_users = data_tensor.shape[0]\n",
    "    all_reconstructions = []\n",
    "\n",
    "    for start_idx in range(0, num_users, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_users)\n",
    "        batch_data = data_tensor[start_idx:end_idx]\n",
    "        batch_cond = user_conditional[start_idx:end_idx]\n",
    "        recon_batch, mu, logvar = model(batch_data, batch_cond)\n",
    "        recon_batch = recon_batch.cpu()\n",
    "        all_reconstructions.append(recon_batch)\n",
    "\n",
    "    reconstructions = torch.cat(all_reconstructions, dim=0)\n",
    "\n",
    "# 5. 이미 본 아이템 제외\n",
    "reconstructions = reconstructions.numpy()\n",
    "data_array = full_interaction_matrix.toarray()\n",
    "reconstructions[data_array.nonzero()] = -np.inf\n",
    "\n",
    "# 6. 상위 N개 아이템 선택\n",
    "top_N = 10\n",
    "recommendations = np.argpartition(-reconstructions, top_N, axis=1)[:, :top_N]\n",
    "sorted_recommendations = np.argsort(-reconstructions[np.arange(num_users)[:, None], recommendations], axis=1)\n",
    "top_items = recommendations[np.arange(num_users)[:, None], sorted_recommendations]\n",
    "\n",
    "# 7. 제출 파일 작성\n",
    "users = np.repeat(np.arange(num_users), top_N)\n",
    "items = top_items.flatten()\n",
    "\n",
    "idx2usr_dict = {v: k for k, v in usr2idx_dict.items()}\n",
    "idx2item_dict = {v: k for k, v in item2idx_dict.items()}\n",
    "\n",
    "users = [idx2usr_dict[u] for u in users]\n",
    "items = [idx2item_dict[i] for i in items]\n",
    "\n",
    "submission_df = pd.DataFrame({'user': users, 'item': items})\n",
    "submission_df.to_csv(\"/data/ephemeral/home/code/output/CVAE_1:1_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
